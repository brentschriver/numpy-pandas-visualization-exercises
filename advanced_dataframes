import pandas as pd
import numpy as np
from pydataset import data
from function_exercises import string_cheese_to_processed_cheese

mpg = data('mpg')

# 4. Use your function to obtain a connection to the 'employees' database.
def get_db_url(db_name):
    from env import host, user, password
    return f'mysql+pymysql://{user}:{password}@{host}/{db_name}'

employees_sql = '''
    select * from employees limit 3000
'''
titles_sql = '''
    select * from titles limit 3000
'''
dept_sql = '''
    select * from departments limit 3000
'''

url = get_db_url('employees')

employees_df = pd.read_sql(employees_sql, url)
titles_df = pd.read_sql(titles_sql, url)
dept_df = pd.read_sql(dept_sql, url)

#print(employees_df.head())

# 5. Once you have successfully run a query:
#   a. Intentionally make a typo in the database url. What kind of error message do you see?
'''
Exception has occurred: OperationalError       (note: full exception trace is shown but execution is paused at: <module>)
(pymysql.err.OperationalError) (1044, "Access denied for user 'hopper_1554'@'%' to database 'employxees'")
(Background on this error at: http://sqlalche.me/e/14/e3q8)

The above exception was the direct cause of the following exception:

  File "/Users/brent/codeup-data-science/numpy-pandas-visualization-exercises/advanced_dataframes", line 13, in <module> (Current frame)
    df = pd.read_sql(sql, url)
'''
#   b. Intentionally make an error in your SQL query. What does the error message look like?
'''
Exception has occurred: ProgrammingError       (note: full exception trace is shown but execution is paused at: <module>)
(pymysql.err.ProgrammingError) (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'from employees limit 3000' at line 1")
[SQL: 
    select d* from employees limit 3000
]
(Background on this error at: http://sqlalche.me/e/14/f405)

The above exception was the direct cause of the following exception:

  File "/Users/brent/codeup-data-science/numpy-pandas-visualization-exercises/advanced_dataframes", line 13, in <module> (Current frame)
    df = pd.read_sql(sql, url)
'''

# 6. Read the employees and titles tables into two separate DataFrames.
titles_sql = '''
    select * from titles limit 3000
'''

titles_df = pd.read_sql(titles_sql, url)

#print(titles_df.head())

# 7. How many rows and columns do you have in each DataFrame? Is that what you expected?
# There are six columns in the 'employees' df and four columns in the 'titles' df.
# There are only 5 rows because I used the .head() function. 
# The result is exactlye what I expected.


# 8. Display the summary statistics for each DataFrame
# print(employees_df.info())
# print(employees_df.describe())
# print(titles_df.info())
# print(titles_df.describe())


# 9. How many unique titles are in the 'titles' DataFrame
unique_titles_sql = '''
select count(distinct(title)) from titles
'''

users = pd.DataFrame({
    'id': [1, 2, 3, 4, 5, 6],
    'name': ['bob', 'joe', 'sally', 'adam', 'jane', 'mike'],
    'role_id': [1, 2, 3, 3, np.nan, np.nan]
})

roles = pd.DataFrame({
    'id': [1, 2, 3, 4],
    'name': ['admin', 'author', 'reviewer', 'commenter']
})



# Exercises II
# 2.
#print(users.merge(roles, how = 'right'))


# 3. 
#print(users.merge(roles, how = 'outer'))


# 4.
#print(users.merge(roles).drop(columns = 'role_id'))


# 5. Load the 'mpg' dataset from PyDataset


# 6. Output and read the documentations for the 'mpg' dataset.
#print(mpg.info())


# 7. How many rows and columns are in the dataset?
#   There are 234 rows and 11 columns.


# 8. Check out your column names and perform any cleanup you may want on them.
new_df = mpg.rename(columns={'displ': 'display', 'cyl': 'cylinder', 'trans': 'transmission', 'cty': 'city', 'hwy': 'highway'}).drop(columns=['drv', 'fl'])
#print(new_df)

# 9. Display the summary statistics for the dataset.
#print(new_df.describe())


# 10. How many different manufacturers are there?
#print(new_df.groupby('manufacturer').model.count())
#   There are 15 different manufacturers.


# 11. How many different models are there?
#print(new_df.groupby('model').model.count())


# 12. Create a column named 'mileage_difference' like you did in the DataFrames exercises; this column should contain the difference
# between highway and city mileage for each car.
new_df['mileage_difference'] = new_df.highway - new_df.city



# 13. Create a column named 'average_mileage' like you did in the DataFrames exercises; this is the mean of the city and highway mileage.
new_df['average_mileage'] = (new_df.city + new_df.highway)/2


# 14. Create a new column on the 'mpg' dataset named 'is_automatic' that holds boolean values denoting whether
# the car has an automatic transmission.
new_df['is_automatic'] = new_df.transmission.str.startswith('auto')
print(new_df)

# 15. Use the 'mpg' dataset, find out which manufacturer has the best miles per gallon on average?
new_df.groupby('manufacturer')


# Exercise III
# 1. Use your get_db_url function to help you explore the data from the 'chipotle' database.
chipotle_url = get_db_url('chipotle')
chipotle_sql = '''
select * from orders
'''
chipotle_dataframe = pd.read_sql(chipotle_sql, chipotle_url)
#print(chipotle_dataframe.info())
chipotle_dataframe.item_price = chipotle_dataframe.item_price.str.replace('$','').astype('float')
#print(chipotle_dataframe.groupby('order_id').item_price.sum())


# 3. What are the three most popular items.
item_count = chipotle_dataframe.groupby('item_name').quantity.agg('sum').sort_values(ascending=False).head(3)
print(item_count)


# 4. Which item has produced the most revenue.
most_cheese = chipotle_dataframe.groupby('item_name').item_price.agg('sum').sort_values(ascending=False).head(1)
#print(most_cheese)


# 5. Join the 'employees' and 'titles' DataFrames together.
emp_and_title = employees_df.merge(titles_df, how='inner', on=None, left_on='emp_no', right_on='emp_no')
#print(emp_and_title)

# 6. For each title, find the hire date of the employee that was hired most recently with that title.
newest_hire = emp_and_title.groupby('title').from_date.max()
print(newest_hire)

# 7. Write the code necessary to create a cross tabulation of the number of titles by department. (Hint: this will 
# involve a combination of SQL code to pull the necessary data and python/pandas code to perform the manipulations.)
query = '''
select emp_no , title, dept_name

from employees
join titles using(emp_no)
join dept_emp using(emp_no)
join departments using(dept_no)

where titles.to_date = '9999-01-01'
'''

df = get_db_url
pd.crosstab(df_title, df.dept_name)

#print(employees_df)
#print(titles_df)
#print(dept_df)
